{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooJtNr5dGrH9"
      },
      "source": [
        "**Name: Amir Hossein Haji Mohammad Rezaei**\n",
        "\n",
        "**Student Number: 99109252**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJm9Z1k0cdmh"
      },
      "source": [
        "# Neural-Network with Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDN075MYGesD"
      },
      "source": [
        "In this notebook, you are going to write and implement all the components required to create and train a two-layered neural network using NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3FdxgNcdmm"
      },
      "source": [
        "## Imports & Seeding:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPZ4zlnxqhl5"
      },
      "source": [
        "Importing some common libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et7OS7TGcdmn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa2v2-xbcdmo"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKWqV2Gycdmp"
      },
      "source": [
        "You'll train and evaluate your model on [Fashion MNIST](https://en.wikipedia.org/wiki/Fashion_MNIST) dataset. In this section, you'll download Fashion MNIST and split it into training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMYZtSoLc7c-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18253ed-bdf1-4e10-ad1b-dc354b461a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Using `fetch_openml`, download `Fashion-MNIST`\n",
        "# and save the training data and labels in `X` and `y` respectively.\n",
        "#############################\n",
        "# Your code goes here (5 points)\n",
        "dataset = fetch_openml(name = 'Fashion-MNIST')\n",
        "\n",
        "X = dataset['data']\n",
        "y = dataset['target']\n",
        "#############################\n",
        "\n",
        "# Normalization:\n",
        "X = ((X / 255.) - .5) * 2\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDmxyMJ4dBk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e20e937-7c1d-420b-c115-6de558dde6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000,) (10000, 784) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Using `train_test_split`, split your data into two sets.\n",
        "# Set the test_size to 10000\n",
        "\n",
        "#############################\n",
        "# Your code goes here (6 points)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 10000)\n",
        "#############################\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiGTXGXKcdmt"
      },
      "source": [
        "## Prepare training & validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba3nNYlDcdmt"
      },
      "source": [
        "We'll use only 3 classes from Fashion MNIST: Trouser, T-shirt, and Sneaker classes.\n",
        "\n",
        "The class labels for T-shirt, Trouser, and Sneaker are 0, 1, and 7 respectively.\n",
        "\n",
        "In this part, you'll limit the testing and training sets to only these three classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcBDZEtzcdmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85925f46-c512-4fbc-f44f-a1343b42975c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18022, 784) (18022,)\n"
          ]
        }
      ],
      "source": [
        "# Modify `y_train` and `x_train`.\n",
        "# Only keep the 3 classes mentioned above.\n",
        "#############################\n",
        "# Your code goes here (4 points)\n",
        "\n",
        "selected = (y_train == '0') | (y_train == '1')  | (y_train == '7')\n",
        "\n",
        "x_train = x_train[selected]\n",
        "y_train = y_train[selected]\n",
        "\n",
        "y_train[y_train == '7'] = '2'\n",
        "\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy().astype(np.int32)\n",
        "#############################\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX2hkRe1cdmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29afdc37-4b1e-4d1a-eacd-b900418080d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2978, 784) (2978,)\n"
          ]
        }
      ],
      "source": [
        "# Modify `y_test` and `x_test`.\n",
        "# Only keep the 3 classes mentioned above.\n",
        "#############################\n",
        "# Your code goes here (4 points)\n",
        "\n",
        "selected = (y_test == '0') | (y_test == '1')  | (y_test == '7')\n",
        "\n",
        "x_test = x_test[selected]\n",
        "y_test = y_test[selected]\n",
        "\n",
        "y_test[y_test == '7'] = '2'\n",
        "\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy().astype(np.int32)\n",
        "#############################\n",
        "\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv6SMLUktWbv"
      },
      "source": [
        "## Linear & Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXlyJo5JteKC"
      },
      "source": [
        "In this part, you'll implement the forward and backward process for the following components:\n",
        "- Softmax Layer\n",
        "- Linear Layer\n",
        "- ReLU Layer\n",
        "- Sigmoid Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXtAD5uYA4sQ"
      },
      "source": [
        "### The `Softmax` Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzaIVo-_Axp7"
      },
      "outputs": [],
      "source": [
        "def logsumexp(array, axis=1):\n",
        "    \"\"\"\n",
        "    calculate log(sum(exp(array))) using np.logaddexp\n",
        "\n",
        "    Args:\n",
        "        array : input array\n",
        "        axis : reduce axis, 1 means columns and 0 means rows\n",
        "    \"\"\"\n",
        "    assert len(array) >= 2\n",
        "    ans = None\n",
        "    if axis == 0:\n",
        "        for i in range(array.shape[0] - 1):\n",
        "            if i == 0:\n",
        "                ans = np.logaddexp(array[0, :], array[1, :])\n",
        "            else:\n",
        "                ans = np.logaddexp(ans, array[i + 1, :])\n",
        "\n",
        "    else:\n",
        "        for i in range(array.shape[1] - 1):\n",
        "            if i == 0:\n",
        "                ans = np.logaddexp(array[:, 0], array[:, 1])\n",
        "            else:\n",
        "                ans = np.logaddexp(ans, array[:, i + 1])\n",
        "\n",
        "    return ans\n",
        "\n",
        "\n",
        "# Implemented LogSoftmax for having simple computation of backward gradients\n",
        "class LogSoftMaxLayer(object):\n",
        "    def __init__(self):\n",
        "        self.inp = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Write the forward pass for softmax.\n",
        "        # Save the values required for the backward pass.\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "\n",
        "        # Shift the input by its maximum value to prevent overflow of values in output\n",
        "        shifted = x - np.max(x, axis=1, keepdims=True)\n",
        "        sums = logsumexp(x)\n",
        "        y = (x.T - sums).T\n",
        "        self.output = y\n",
        "        self.inp = shifted\n",
        "        #############################\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, up_grad):\n",
        "        # Write the backward pass for softmax.\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "\n",
        "        down_grad = None\n",
        "        x = self.inp\n",
        "        m, n = x.shape\n",
        "\n",
        "        result = []\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                sums = 0\n",
        "                row = np.sum(np.exp(x[i, :]))\n",
        "                for k in range(n):\n",
        "                    if k == j:\n",
        "                        sums += up_grad[i, k] * (1 - (np.exp(x[i, j])/row))\n",
        "                    else:\n",
        "                        sums += up_grad[i, k] * - (np.exp(x[i, j])/row)\n",
        "                result.append(sums)\n",
        "\n",
        "        down_grad = np.array(result).reshape(x.shape)\n",
        "        #############################\n",
        "        return down_grad\n",
        "\n",
        "    def step(self, optimizer):\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcFoIDZjcdnB"
      },
      "source": [
        "### The `Linear` Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1strsTh6cdnG"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        # Initialize the layer's weights and biases\n",
        "        #############################\n",
        "        # Your code goes here (2 points)\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.w = np.random.randn(in_dim, out_dim) * np.sqrt(6 / out_dim)\n",
        "        self.b = np.zeros(out_dim)\n",
        "        #############################\n",
        "        self.inp = None\n",
        "        self.dw = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Compute linear layer's output.\n",
        "        # Save the value(s) required for the backward phase.\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        self.inp = inp\n",
        "        z = np.dot(inp, self.w) + self.b\n",
        "        #############################\n",
        "\n",
        "        return z\n",
        "\n",
        "    def backward(self, up_grad):\n",
        "        # Calculate the gradient with respect to the weights\n",
        "        # and biases and save the results.\n",
        "        #############################\n",
        "        # Your code goes here (6 points)\n",
        "\n",
        "        down_grad = np.dot(up_grad, self.w.T)\n",
        "        self.dw = np.dot(self.inp.T, up_grad)\n",
        "        self.db = np.sum(up_grad, axis = 0)\n",
        "        #############################\n",
        "        return down_grad\n",
        "\n",
        "    def step(self, optimizer):\n",
        "      # Update the layer's weights and biases\n",
        "      # Update previous_w_update and previous_b_update accordingly\n",
        "      #############################\n",
        "      # Your code goes here (5 points)\n",
        "      self.w = optimizer.get_next_update(self.w, self.dw)\n",
        "      self.b = optimizer.get_next_update(self.b, self.db)\n",
        "      #############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Lfo-nhcdnG"
      },
      "source": [
        "### The `ReLU` Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN6vcirMcdnH"
      },
      "outputs": [],
      "source": [
        "class RelU:\n",
        "    def __init__(self):\n",
        "        self.inp = None\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Write the forward pass for ReLU.\n",
        "        # Save the value(s) required for the backward pass.\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        self.inp = inp\n",
        "        output = (np.abs(inp) + inp) / 2\n",
        "        #############################\n",
        "        return output\n",
        "\n",
        "    def backward(self, up_grad):\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        filter = (self.inp > 0)\n",
        "        down_grad = filter * up_grad\n",
        "        #############################\n",
        "        return down_grad\n",
        "\n",
        "    def step(self, optimizer):\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z00KoSI3cdnJ"
      },
      "source": [
        "### The `sigmoid` Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTYYeL2lcdnJ"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def forward(self, inp):\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        self.out = 1 / (1 + np.exp(-inp))\n",
        "        #############################\n",
        "        return self.out\n",
        "\n",
        "    def backward(self, up_grad):\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        down_grad = self.out * (1 - self.out) * up_grad\n",
        "        #############################\n",
        "        return down_grad\n",
        "\n",
        "    def step(self, optimizer):\n",
        "      pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zngleGY2cdnK"
      },
      "source": [
        "## `Loss` function :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISedT4FvcdnK"
      },
      "source": [
        "For this task we are going to use the [Cross-Entropy Loss](https://en.wikipedia.org/wiki/Cross_entropy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQyz4ybycdnL"
      },
      "outputs": [],
      "source": [
        "class CELoss():\n",
        "    def __init__(self):\n",
        "      pass\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "\n",
        "        self.log_yhat = pred\n",
        "        self.y = target\n",
        "        m = self.y.shape[0]\n",
        "        # Commpute and return the loss\n",
        "        #############################\n",
        "        # Your code goes here (8 points)\n",
        "        selected = self.log_yhat[range(m), self.y]\n",
        "\n",
        "        loss = -np.sum(selected)\n",
        "        loss /= m\n",
        "\n",
        "        return loss\n",
        "        #############################\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        # Derivative of loss_fn with respect to a the predicted label.\n",
        "        # Use `self.y` and `self.yhat` to compute and return `grad`.\n",
        "        #############################\n",
        "        # Your code goes here (6 points)\n",
        "        grad = None\n",
        "        m, n = self.log_yhat.shape\n",
        "\n",
        "        result = []\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                if j != self.y[i]:\n",
        "                    result.append(0)\n",
        "                else:\n",
        "                    result.append(-1/m)\n",
        "\n",
        "        grad = np.array(result).reshape(m, n)\n",
        "        #############################\n",
        "        return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xovZI-70kB9I"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "In this section, you'll implement an optimizer classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5ADTi5tkVTS"
      },
      "outputs": [],
      "source": [
        "class GradientDescent(object):\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def get_next_update(self, x, dx):\n",
        "        # Compute the new value for 'x' and return the result\n",
        "        #############################\n",
        "        # Your code goes here (2 points)\n",
        "        result = x - self.lr * dx\n",
        "        return result\n",
        "        #############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxxrEEovYEFi"
      },
      "source": [
        "## The Model\n",
        "Now you'll write the base class for a multi-layer perceptron network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8SoZeYRcdnY"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    def __init__(self, layers, loss_fn, optimizer):\n",
        "        self.layers = layers\n",
        "        self.losses  = []\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Pass `inp` to all the layers sequentially\n",
        "        # and return the result.\n",
        "        #############################\n",
        "        # Your code goes here (4 points)\n",
        "        x = inp\n",
        "        for l in self.layers:\n",
        "          x = l.forward(x)\n",
        "        return x\n",
        "        #############################\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        loss = self.loss_fn.forward(pred, label)\n",
        "        self.losses.append(loss)\n",
        "        return loss\n",
        "\n",
        "    def backward(self):\n",
        "        # Start with loss function's gradient and\n",
        "        # do the backward pass on all the layers.\n",
        "        #############################\n",
        "        # Your code goes here (5 points)\n",
        "        up_stream = self.loss_fn.backward()\n",
        "\n",
        "        for i in range(len(self.layers) - 1, -1, -1):\n",
        "          up_stream = self.layers[i].backward(up_stream)\n",
        "        #############################\n",
        "\n",
        "    def update(self):\n",
        "        for layer in self.layers:\n",
        "          layer.step(self.optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo0rNwYciueF"
      },
      "source": [
        "The following cell encodes training labels into a one-hot representation with 3 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhJTulaFJ4vR"
      },
      "outputs": [],
      "source": [
        "def onehot_enc(y, num_labels):\n",
        "    ary = np.zeros((y.shape[0], num_labels))\n",
        "    for i, val in enumerate(y):\n",
        "        ary[i, val] = 1\n",
        "    return ary\n",
        "\n",
        "# y_train = onehot_enc(y_train, 3)\n",
        "# There is no need to use one-hot encoding in this implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS6S_RUwsRkF"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, x, y):\n",
        "    for n in range(epochs):\n",
        "      # First do the forward pass. Next, compute the loss.\n",
        "      # Then do the backward pass and finally, update the parameters.\n",
        "      #############################\n",
        "      # Your code goes here (4 points)\n",
        "      pred = model.forward(x)\n",
        "      loss = model.loss(pred, y)\n",
        "      model.backward()\n",
        "      model.update()\n",
        "      #############################\n",
        "      print(f\"Loss at {n}: {loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1lSq2jNcdnY",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3052f07-0ce7-4202-f501-7897571ced7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at 0: 1.030\n",
            "Loss at 1: 1.024\n",
            "Loss at 2: 1.018\n",
            "Loss at 3: 1.012\n",
            "Loss at 4: 1.004\n",
            "Loss at 5: 0.996\n",
            "Loss at 6: 0.987\n",
            "Loss at 7: 0.978\n",
            "Loss at 8: 0.969\n",
            "Loss at 9: 0.959\n",
            "Loss at 10: 0.950\n",
            "Loss at 11: 0.941\n",
            "Loss at 12: 0.932\n",
            "Loss at 13: 0.924\n",
            "Loss at 14: 0.914\n",
            "Loss at 15: 0.906\n",
            "Loss at 16: 0.899\n",
            "Loss at 17: 0.893\n",
            "Loss at 18: 0.886\n",
            "Loss at 19: 0.879\n",
            "Loss at 20: 0.874\n",
            "Loss at 21: 0.868\n",
            "Loss at 22: 0.863\n",
            "Loss at 23: 0.858\n",
            "Loss at 24: 0.854\n",
            "Loss at 25: 0.850\n",
            "Loss at 26: 0.847\n",
            "Loss at 27: 0.843\n",
            "Loss at 28: 0.840\n",
            "Loss at 29: 0.837\n",
            "Loss at 30: 0.834\n",
            "Loss at 31: 0.831\n",
            "Loss at 32: 0.828\n",
            "Loss at 33: 0.824\n",
            "Loss at 34: 0.821\n",
            "Loss at 35: 0.818\n",
            "Loss at 36: 0.815\n",
            "Loss at 37: 0.812\n",
            "Loss at 38: 0.809\n",
            "Loss at 39: 0.806\n",
            "Loss at 40: 0.804\n",
            "Loss at 41: 0.802\n",
            "Loss at 42: 0.799\n",
            "Loss at 43: 0.797\n",
            "Loss at 44: 0.795\n",
            "Loss at 45: 0.793\n",
            "Loss at 46: 0.791\n",
            "Loss at 47: 0.789\n",
            "Loss at 48: 0.788\n",
            "Loss at 49: 0.786\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the `MLP` with the following structure:\n",
        "#     Linear with 50 units --> ReLU --> Linear with 50 units --> ReLU --> Linear with 3 units --> Sigmoid --> Softmax\n",
        "# Use GradientDescent as the optimizer, set the learning rate to 0.001, and use CELoss as the loss function.\n",
        "#############################\n",
        "# Your code goes here (4 points)\n",
        "\n",
        "layers = [Linear(784, 50), RelU(), Linear(50, 50), RelU(), Linear(50, 3), Sigmoid(), LogSoftMaxLayer()]\n",
        "optimizer = GradientDescent(lr = 0.01)\n",
        "loss_fn = CELoss()\n",
        "\n",
        "nn = MLP(layers, loss_fn, optimizer)\n",
        "#############################\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "# Train the network using only `x_train` and `y_train` (no validation)\n",
        "train(nn, epochs, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJec2xRJmY37"
      },
      "source": [
        "Let's plot the loss value for each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymaQNn70cdnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "87ce9ac5-5902-4835-90d9-f139f0929cdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP7UlEQVR4nO3deVhUZcMG8PvMwAz7IiC7IILiCoqKuKQmhUvmVrmb9uZuZubXm7lmr2mbmbtZqanlkmmbWYiK+4bgiguyyyYgu2wz5/uDnCKxkAHODHP/rmuuK545c+aek8ndOc+cRxBFUQQRERGRAZFJHYCIiIiovrEAERERkcFhASIiIiKDwwJEREREBocFiIiIiAwOCxAREREZHBYgIiIiMjgsQERERGRwWICIiIjI4LAAEZFOGT9+PDw9PWv02sWLF0MQhNoNVE3a5Cai+scCRETVIghCtR5Hjx6VOioR0b8SuBYYEVXH9u3bK/389ddfIzQ0FNu2bas0/swzz8DR0bHG71NWVga1Wg2lUvnEry0vL0d5eTlMTExq/P41NX78eBw9ehTx8fH1/t5E9OSMpA5ARPphzJgxlX4+c+YMQkNDHxn/u6KiIpiZmVX7fYyNjWuUDwCMjIxgZMS/1ojo3/ESGBHVml69eqFNmzaIiIjAU089BTMzM7zzzjsAgB9++AEDBgyAi4sLlEolmjVrhvfeew8qlarSPv4+lyY+Ph6CIODjjz/G559/jmbNmkGpVKJTp044f/58pddWNQdIEATMmDED+/fvR5s2baBUKtG6dWscPHjwkfxHjx5Fx44dYWJigmbNmmHjxo1azSsqLCzEm2++CXd3dyiVSrRo0QIff/wx/n7iPTQ0FN27d4eNjQ0sLCzQokULzXF7aPXq1WjdujXMzMxga2uLjh074ptvvqlRLiLiGSAiqmVZWVno168fRowYgTFjxmguh23ZsgUWFhaYPXs2LCwscPjwYSxcuBB5eXn46KOP/nW/33zzDfLz8zF58mQIgoAPP/wQQ4cORWxs7L+eNTpx4gS+//57TJs2DZaWlli1ahWGDRuGxMRE2NnZAQAiIyPRt29fODs7491334VKpcKSJUvg4OBQo+MgiiKef/55HDlyBP/5z3/g7++P3377Df/3f/+Hu3fv4tNPPwUAXLt2Dc899xzatWuHJUuWQKlUIiYmBidPntTsa9OmTZg5cyZeeOEFvP766yguLsbly5dx9uxZjBo1qkb5iAyeSERUA9OnTxf//ldIz549RQDihg0bHtm+qKjokbHJkyeLZmZmYnFxsWbs5ZdfFj08PDQ/x8XFiQBEOzs7MTs7WzP+ww8/iADEn376STO2aNGiRzIBEBUKhRgTE6MZu3TpkghAXL16tWZs4MCBopmZmXj37l3N2O3bt0UjI6NH9lmVv+fev3+/CED83//+V2m7F154QRQEQZPn008/FQGI9+7de+y+Bw0aJLZu3fpfMxBR9fESGBHVKqVSiQkTJjwybmpqqvnn/Px8ZGZmokePHigqKsKNGzf+db/Dhw+Hra2t5ucePXoAAGJjY//1tcHBwWjWrJnm53bt2sHKykrzWpVKhUOHDmHw4MFwcXHRbOft7Y1+/fr96/6rcuDAAcjlcsycObPS+JtvvglRFPHrr78CAGxsbABUXCJUq9VV7svGxgbJycmPXPIjoppjASKiWuXq6gqFQvHI+LVr1zBkyBBYW1vDysoKDg4OmgnUubm5/7rfJk2aVPr5YRm6f//+E7/24esfvjYjIwMPHjyAt7f3I9tVNVYdCQkJcHFxgaWlZaXxli1bap4HKopdt27d8Oqrr8LR0REjRozA7t27K5Wh//73v7CwsEDnzp3h4+OD6dOnV7pERkRPjgWIiGrVX8/0PJSTk4OePXvi0qVLWLJkCX766SeEhobigw8+AIDHnvn4K7lcXuW4WI07eWjz2rpmamqKY8eO4dChQxg7diwuX76M4cOH45lnntFMEG/ZsiVu3ryJnTt3onv37ti7dy+6d++ORYsWSZyeSH+xABFRnTt69CiysrKwZcsWvP7663juuecQHBxc6ZKWlBo3bgwTExPExMQ88lxVY9Xh4eGBlJQU5OfnVxp/eLnPw8NDMyaTydCnTx+sWLEC169fx9KlS3H48GEcOXJEs425uTmGDx+OzZs3IzExEQMGDMDSpUtRXFxco3xEho4FiIjq3MMzMH8941JaWop169ZJFakSuVyO4OBg7N+/HykpKZrxmJgYzVydJ9W/f3+oVCqsWbOm0vinn34KQRA0c4uys7Mfea2/vz8AoKSkBEDFN+v+SqFQoFWrVhBFEWVlZTXKR2To+DV4IqpzXbt2ha2tLV5++WXMnDkTgiBg27ZtOnEJ6qHFixfj999/R7du3TB16lRNeWnTpg2ioqKeeH8DBw5E7969MW/ePMTHx8PPzw+///47fvjhB8yaNUszKXvJkiU4duwYBgwYAA8PD2RkZGDdunVwc3ND9+7dAQDPPvssnJyc0K1bNzg6OiI6Ohpr1qzBgAEDHpljRETVwwJERHXOzs4OP//8M958803Mnz8ftra2GDNmDPr06YOQkBCp4wEAAgIC8Ouvv2LOnDlYsGAB3N3dsWTJEkRHR1frW2p/J5PJ8OOPP2LhwoXYtWsXNm/eDE9PT3z00Ud48803Nds9//zziI+Px1dffYXMzEzY29ujZ8+eePfdd2FtbQ0AmDx5Mnbs2IEVK1agoKAAbm5umDlzJubPn19rn5/I0HAtMCKifzB48GBcu3YNt2/fljoKEdUizgEiIvrDgwcPKv18+/ZtHDhwAL169ZImEBHVGZ4BIiL6g7OzM8aPHw8vLy8kJCRg/fr1KCkpQWRkJHx8fKSOR0S1iHOAiIj+0LdvX3z77bdIS0uDUqlEUFAQ3n//fZYfogaIZ4CIiIjI4HAOEBERERkcFiAiIiIyOJwDVAW1Wo2UlBRYWlpCEASp4xAREVE1iKKI/Px8uLi4QCb753M8LEBVSElJgbu7u9QxiIiIqAaSkpLg5ub2j9uwAFXh4a3lk5KSYGVlJXEaIiIiqo68vDy4u7tXa4kYFqAqPLzsZWVlxQJERESkZ6ozfYWToImIiMjgsAARERGRwWEBIiIiIoPDAkREREQGhwWIiIiIDA4LEBERERkcFiAiIiIyOCxAREREZHBYgIiIiMjgsAARERGRwWEBIiIiIoPDAkREREQGhwWonh26ng61WpQ6BhERkUFjAapHnx+7g1e/voDZu6NQWq6WOg4REZHBYgGqR/YWShjJBOyPSsF/tp5HYUm51JGIiIgMEgtQPRrawQ2bXu4IU2M5jt/OxKhNZ5BVUCJ1LCIiIoPDAlTPerdojG8mBsLWzBiXknPxwobTSMoukjoWERGRQWEBkkD7Jrb4bmpXuNqYIi6zEMPWn0J0ap7UsYiIiAwGC5BEmjlYYO/UrmjhaImM/BK8tOE0zsRmSR2LiIjIILAAScjJ2gS7pwShs2cj5JeUY9xX53DwaqrUsYiIiBo8FiCJWZsa4+v/dMazrRxRWq7GtB0Xsf1MgtSxiIiIGjQWIB1gYizHutEdMLJzE6hFYP7+q/g09BZEkTdMJCIiqgssQDrCSC7D+0PaYGYfHwDAZ2G3Mff7KyhX8YaJREREtY0FSIcIgoDZzzTH/wa3gUwAdp5PwuRtESgq5Q0TiYiIahMLkA4a08UDG8YEQGkkQ9iNDIzadJY3TCQiIqpFLEA66tnWTvhmYiBszIwRlZSDFzacRmIWb5hIRERUG1iAdFiARyN8N+XPGyYOXX8KV+/mSh2LiIhI77EA6Tjvxhb4flpXtHS2QmZBCYZvPI1jt+5JHYuIiEivsQDpAUcrE+ye3AXdvO1QWKrCK1vOY29EstSxiIiI9BYLkJ6wNDHG5vGdMcjfBeVqEW/uuYR1R2N4ryAiIqIaYAHSIwojGT59yR+Tn/ICAHx48Cbe/ek61GqWICIioifBAqRnZDIBc/u3xMLnWgEAtpyKx2s7I1FSrpI4GRERkf5gAdJTr3RvilUj28NYLuCXy6mYsPk88ovLpI5FRESkF1iA9Njzfi7YPL4zzBVynLqTheEbzyAjv1jqWERERDqPBUjPdfexx67JQbC3UOB6ah6GrT+FuMxCqWMRERHpNBagBqCNqzX2Tu0KDzszJGU/wAvrT+Fyco7UsYiIiHQWC1AD4WFnju+mdEUbVytkFZZixOdneMNEIiKix2ABakAcLJXYOSkI3b3tUfTHDRP3R96VOhYREZHOYQFqYCyURvhqfCc871dxw8RZu6Lw06UUqWMRERHpFBagBkhhJMPK4f4Y06UJAODN3ZdwNjZL4lRERES6gwWogZLJBLz7fBv0be2EUpUaE7++gNvp+VLHIiIi0gksQA2YXCZg5Qh/BHjYIq+4HOM3n0d6Hu8TRERExALUwJkYy7FpXEc0tTfH3ZwHmLD5PApKyqWORUREJCkWIAPQyFyBrRM6a26WOG3HRZSp1FLHIiIikgwLkIFoYmeGL1/uBFNjOY7duod5+65AFLmKPBERGSYWIAPi526DNaPaQyYAuy8k47Ow21JHIiIikgQLkIHp09IR7w1uAwBYeeg2dl9IkjgRERFR/WMBMkCjAz0wrVczAMDc768gnEtmEBGRgWEBMlD/F9ICQ9q7QqUWMW17BK6n5EkdiYiIqN6wABkoQRDwwbB26NrMDoWlKkzefgH3C0uljkVERFQvWIAMmMJIhnWjO6BJIzMkZT/AzJ2RKOfX44mIyABIWoCOHTuGgQMHwsXFBYIgYP/+/f/6mqNHj6JDhw5QKpXw9vbGli1bHtlm7dq18PT0hImJCQIDA3Hu3LnaD99A2JgpsHFsAEyN5Th+OxMf/X5T6khERER1TtICVFhYCD8/P6xdu7Za28fFxWHAgAHo3bs3oqKiMGvWLLz66qv47bffNNvs2rULs2fPxqJFi3Dx4kX4+fkhJCQEGRkZdfUx9F5LZyt89GI7AMDG8Fj8fJmrxxMRUcMmiDpyNzxBELBv3z4MHjz4sdv897//xS+//IKrV69qxkaMGIGcnBwcPHgQABAYGIhOnTphzZo1AAC1Wg13d3e89tprePvtt6uVJS8vD9bW1sjNzYWVlVXNP5SeWfZrNDaGx8LUWI7vp3VFS2fD+exERKT/nuT3t17NATp9+jSCg4MrjYWEhOD06dMAgNLSUkRERFTaRiaTITg4WLNNVUpKSpCXl1fpYYjeCvFFDx97PChTYfK2COQUcVI0ERE1THpVgNLS0uDo6FhpzNHREXl5eXjw4AEyMzOhUqmq3CYtLe2x+122bBmsra01D3d39zrJr+vkMgGrRrSHeyNTJGYXYebOKKjUOnGCkIiIqFbpVQGqK3PnzkVubq7mkZRkuHdHtjVXYOOYjjAxluHYrXv4hJOiiYioAdKrAuTk5IT09PRKY+np6bCysoKpqSns7e0hl8ur3MbJyemx+1UqlbCysqr0MGStXKzwwbCKSdHrjt7BgSupEiciIiKqXXpVgIKCghAWFlZpLDQ0FEFBQQAAhUKBgICAStuo1WqEhYVptqHqGeTviok9mgIA5uy5hJtp+RInIiIiqj2SFqCCggJERUUhKioKQMXX3KOiopCYmAig4tLUuHHjNNtPmTIFsbGxeOutt3Djxg2sW7cOu3fvxhtvvKHZZvbs2di0aRO2bt2K6OhoTJ06FYWFhZgwYUK9fraG4L99fdHN2w5FpSpM2nYBuUVlUkciIiKqFZIWoAsXLqB9+/Zo3749gIry0r59eyxcuBAAkJqaqilDANC0aVP88ssvCA0NhZ+fHz755BN88cUXCAkJ0WwzfPhwfPzxx1i4cCH8/f0RFRWFgwcPPjIxmv6dkVyG1SM7wNXGFAlZRZi9Owo6ctcEIiIirejMfYB0iaHeB+hxrt7NxdD1p1Barsa8/i0x8SkvqSMRERE9osHeB4ik0cbVGgufawUA+ODgDVxMvC9xIiIiIu2wAFG1jA5sgufaOaNcLeK1byJ5k0QiItJrLEBULYIgYNnQtvC0M8PdnAeYs+cy5wMREZHeYgGiarM0McaaUR2gkMtwKDodX56IkzoSERFRjbAA0RNp42qNBQMr5gMt//UGIjkfiIiI9BALED2xMYFNMKBtxXygGZwPREREeogFiJ6YIAhYNqwtPDgfiIiI9BQLENWIlYkx1v5lPtBXJ+OljkRERFRtLEBUY21crbHguZYAgOW/RiMqKUfaQERERNXEAkRaGdPFA/3bOqFMJWL6jotcL4yIiPQCCxBpRRAELB/WDk0a/TEf6LtLnA9EREQ6jwWItPbX+UCh19Ox6Xis1JGIiIj+EQsQ1Yq2btZYOPDhemE3cTY2S+JEREREj8cCRLVmdGATDGnvCpVaxIxvI5GRXyx1JCIioiqxAFGtEQQBS4e0QXNHC9zLL8Hr30ahXKWWOhYREdEjWICoVpkpjLBudADMFXKcjs3CitBbUkciIiJ6BAsQ1TrvxhZYPqwdAGDd0TsIi06XOBEREVFlLEBUJwb6uWB8V08AwBu7opCUXSRtICIior9gAaI6807/lvB3t0FecTmm7biI4jKV1JGIiIgAsABRHVIYybB2dAfYmhnjyt1cvPfzdakjERERAWABojrmamOKT4f7QxCAHWcTsS8yWepIRERELEBU93q1aIzXnvYBALzz/VXcSs+XOBERERk6FiCqF6/38UF3b3s8KFNh6vYIFJWWSx2JiIgMGAsQ1Qu5TMBnI/zhaKXEnXuFWPpLtNSRiIjIgLEAUb2xs1Dikxf9AVTMB+L9gYiISCosQFSvuvvY49XuTQEAb313GffySyROREREhogFiOrdnJAW8HWyRFZhKf679zJEUZQ6EhERGRgWIKp3JsZyrBzhD4WRDIdvZGD72USpIxERkYFhASJJ+DpZ4b99fQEAS3+5jpiMAokTERGRIWEBIslM6OqJHj72KC5TY9auSJSWq6WOREREBoIFiCQjkwn4+EU/2JgZ4+rdPKw8dEvqSEREZCBYgEhSjlYmWD60LQBgffgdnI3NkjgREREZAhYgklzfNs54McANogjM3n0JecVlUkciIqIGjgWIdMKi51ujSSMz3M15gIX7r0odh4iIGjgWINIJFkojfDrcHzIB2B+Vgh+i7kodiYiIGjAWINIZAR62mPHHqvHz919FSs4DiRMREVFDxQJEOmXm097wd7dBfnE53v7+Cu8STUREdYIFiHSKkVyGT17yg9JIhmO37mHX+SSpIxERUQPEAkQ6p5mDBf4vpAUA4H+/RCP5fpHEiYiIqKFhASKdNKFbU3T0sEVBSTkXTCUiolrHAkQ6SS4T8NGLfjAxluFkTBZ2cMFUIiKqRSxApLOa2ptrFkx9/0A0krJ5KYyIiGoHCxDptJeDPNG5aSMUlarwf99dglrNS2FERKQ9FiDSaTKZgI9f8IOZQo4zsdnYdiZB6khERNQAsACRzmtiZ4a5/SouhS3/9QbiMwslTkRERPqOBYj0wuhAD3RtZocHZbwURkRE2mMBIr0gkwn4YFg7mCvkOB9/H5tPxUsdiYiI9BgLEOkN90ZmmDegFQDgw4M3EHuvQOJERESkr1iASK+M7OyOHj72KClXY86eS1DxUhgREdUACxDpFUGouBRmqTTCxcQcbAi/I3UkIiLSQyxApHdcbEyxcGDFpbAVobcQmXhf4kRERKRvWIBIL70Q4IaBfi5QqUXM3BmJ/OIyqSMREZEeYQEivSQIApYOaQM3W1MkZT/Agv1XpY5ERER6hAWI9JaViTE+G9EecpmA/VEp+P5istSRiIhIT7AAkV4L8LDFrD4+AIAF+6/yLtFERFQtLECk96b19kZg00YoLFXh9Z2RKC1XSx2JiIh0HAsQ6T25TMCnw/1hbWqMS8m5+CT0ptSRiIhIx7EAUYPgYmOKD4a1AwBsDI/FiduZEiciIiJdJnkBWrt2LTw9PWFiYoLAwECcO3fusduWlZVhyZIlaNasGUxMTODn54eDBw9W2mbx4sUQBKHSw9fXt64/BumAvm2cMCqwCQDgjd1RyCookTgRERHpKkkL0K5duzB79mwsWrQIFy9ehJ+fH0JCQpCRkVHl9vPnz8fGjRuxevVqXL9+HVOmTMGQIUMQGRlZabvWrVsjNTVV8zhx4kR9fBzSAQsGtIJPYwvcyy/B/313GaLIpTKIiOhRkhagFStWYOLEiZgwYQJatWqFDRs2wMzMDF999VWV22/btg3vvPMO+vfvDy8vL0ydOhX9+/fHJ598Umk7IyMjODk5aR729vb18XFIB5gq5Fg1sj0URjIcvpGBrVw1noiIqiBZASotLUVERASCg4P/DCOTITg4GKdPn67yNSUlJTAxMak0Zmpq+sgZntu3b8PFxQVeXl4YPXo0EhMT/zFLSUkJ8vLyKj1If7V0tsI7/Soue77/6w1cT+G/TyIiqkyyApSZmQmVSgVHR8dK446OjkhLS6vyNSEhIVixYgVu374NtVqN0NBQfP/990hNTdVsExgYiC1btuDgwYNYv3494uLi0KNHD+Tn5z82y7Jly2Btba15uLu7186HJMm83NUTfXwbo7RcjWk7IpD7gEtlEBHRnySfBP0kPvvsM/j4+MDX1xcKhQIzZszAhAkTIJP9+TH69euHF198Ee3atUNISAgOHDiAnJwc7N69+7H7nTt3LnJzczWPpKSk+vg4VIcEQcBHL/rB1cYU8VlFmLUzEmo15wMREVEFyQqQvb095HI50tPTK42np6fDycmpytc4ODhg//79KCwsREJCAm7cuAELCwt4eXk99n1sbGzQvHlzxMTEPHYbpVIJKyurSg/Sf43MFdg4NgBKIxmO3LyHlWG3pY5EREQ6QrICpFAoEBAQgLCwMM2YWq1GWFgYgoKC/vG1JiYmcHV1RXl5Ofbu3YtBgwY9dtuCggLcuXMHzs7OtZad9EcbV2ssG9oWALAq7DZCr6f/yyuIiMgQSHoJbPbs2di0aRO2bt2K6OhoTJ06FYWFhZgwYQIAYNy4cZg7d65m+7Nnz+L7779HbGwsjh8/jr59+0KtVuOtt97SbDNnzhyEh4cjPj4ep06dwpAhQyCXyzFy5Mh6/3ykG4Z2cMP4rp4AgNm7onDnXoG0gYiISHJGUr758OHDce/ePSxcuBBpaWnw9/fHwYMHNROjExMTK83vKS4uxvz58xEbGwsLCwv0798f27Ztg42NjWab5ORkjBw5EllZWXBwcED37t1x5swZODg41PfHIx0yb0BLXE/Jw7n4bEzeFoH907vBQinpH38iIpKQIPJOcY/Iy8uDtbU1cnNzOR+oAcnIL8bA1SeQnleCvq2dsH5MBwiCIHUsIiKqJU/y+1uvvgVGpI3GliZYPyYACrkMB6+lYd3RO1JHIiIiibAAkUHp0MQW7w5qDQD4+PebOHqz6mVXiIioYWMBIoMzsnMTjOzsDlEEXt8ZhcSsIqkjERFRPWMBIoO0+PnW8He3Qe6DMkzadgFFpeVSRyIionrEAkQGSWkkx/oxHWBvocCNtHzM/f4KV44nIjIgLEBksJytTbF2VAfIZQJ+iErB7gtcAoWIyFCwAJFBC/Syw5xnWwAAFv14DTfTHr9oLhERNRwsQGTwJj/lhaeaO6C4TI0Z31zkfCAiIgPAAkQGTyYTsOIlPzS2VOJ2RgEW/3hN6khERFTHWICIANhbKLFyhD8EAdh9IRn7I+9KHYmIiOoQCxDRH7o2s8fMp30AAPP2XUEsF00lImqwWICI/mJmHx908WqEwlIVZnwTieIyldSRiIioDrAAEf2FXCbgsxHt0chcgeupeXj/QLTUkYiIqA6wABH9jaOVCVa85AcA+Pp0An69kipxIiIiqm0sQERV6NWiMSb39AIAvLX3MpKyuV4YEVFDwgJE9Bhznm2B9k1skF9cjhnfRqK0XC11JCIiqiUsQESPYSyXYfXI9rAyMcKlpBx89NsNqSMREVEtYQEi+gdutmb46MWK+UCbjsfh92tpEiciIqLawAJE9C9CWjvhlW5NAQBv7rmEhKxCiRMREZG2WICIqmFuf18EeNgiv7gcU7df5P2BiIj0HAsQUTUYy2VYM+rP+wMt+oHrhRER6TMWIKJqcrY2xaoR7SEIwK4LSdh9IUnqSEREVEMsQERPoLuPPWYHNwcALNh/FddT8iRORERENcECRPSEpvf2Rq8WDigpV2PajgjkFZdJHYmIiJ4QCxDRE5LJBHz6kj9cbUwRn1WEObsvQRRFqWMREdETYAEiqgFbcwXWje4AY7mA36+n44vjcVJHIiKiJ8ACRFRDfu42WPhcKwDA8oM3cC4uW+JERERUXSxARFoY08UDg/xdoFKLmPHNRWTkF0sdiYiIqoEFiEgLgiBg2dC28GlsgYz8Esz8NhLlKi6aSkSk61iAiLRkpjDC+jEBMFPIcSY2G2uP3JE6EhER/QsWIKJa4N3YAu8PaQsA+CzsFi7Ecz4QEZEuYwEiqiWD27tiSHtXqEXg9Z1RyH3A+wMREekqFiCiWrRkUGs0aWSGuzkPMG/fFd4fiIhIR7EAEdUiSxNjfDbCH3KZgJ8vp+K7iGSpIxERURVYgIhqWfsmtpj9TMV6YYt+vIa4zEKJExER0d+xABHVgSk9m6GLVyMUlarw+s5IlJbzq/FERLqEBYioDshlAj4d7g8bM2NcTs7FJ6E3pY5ERER/wQJEVEecrU2xfGg7AMDG8FicuJ0pcSIiInqIBYioDvVt44RRgU0AALN3RyG7sFTiREREBNSwACUlJSE5+c9vt5w7dw6zZs3C559/XmvBiBqKBQNawfuPpTLe+u4SvxpPRKQDalSARo0ahSNHjgAA0tLS8Mwzz+DcuXOYN28elixZUqsBifSdqUKOVSPaQyGX4VB0BrafSZA6EhGRwatRAbp69So6d+4MANi9ezfatGmDU6dOYceOHdiyZUtt5iNqEFq5WGFuf18AwP9+icaNtDyJExERGbYaFaCysjIolUoAwKFDh/D8888DAHx9fZGamlp76YgakPFdPdG7hQNKytWYsi2CS2UQEUmoRgWodevW2LBhA44fP47Q0FD07dsXAJCSkgI7O7taDUjUUAiCgBUv+cPVxhTxWUWYvSsKajXnAxERSaFGBeiDDz7Axo0b0atXL4wcORJ+fn4AgB9//FFzaYyIHmVrrsDGsQFQGskQdiMDqw/HSB2JiMggCWINv5KiUqmQl5cHW1tbzVh8fDzMzMzQuHHjWgsohby8PFhbWyM3NxdWVlZSx6EG6LuIZMzZcwmCAHz5ckc87esodSQiIr33JL+/a3QG6MGDBygpKdGUn4SEBKxcuRI3b97U+/JDVB9eCHDDuCAPiCLw+s4oxHO9MCKielWjAjRo0CB8/fXXAICcnBwEBgbik08+weDBg7F+/fpaDUjUUM0f0AoBHrbILy7H5G0RKCotlzoSEZHBqFEBunjxInr06AEA+O677+Do6IiEhAR8/fXXWLVqVa0GJGqoFEYyrBvdAQ6WStxMz8d/917hTRKJiOpJjQpQUVERLC0tAQC///47hg4dCplMhi5duiAhgTd5I6ouRysTrBvdAUYyAT9dSsGXJ+KkjkREZBBqVIC8vb2xf/9+JCUl4bfffsOzzz4LAMjIyOCkYaIn1MmzERY81woAsOzXGzh9J0viREREDV+NCtDChQsxZ84ceHp6onPnzggKCgJQcTaoffv2tRqQyBCMC/LA0PauUKlFzPjmIlJzH0gdiYioQavx1+DT0tKQmpoKPz8/yGQVPercuXOwsrKCr69vrYasb/waPEnhQakKw9afwvXUPPi522D35C5QGsmljkVEpDee5Pd3jQvQQw9XhXdzc9NmNzqFBYikkpRdhOdWn0DugzIM9nfBipf8IZMJUsciItILdX4fILVajSVLlsDa2hoeHh7w8PCAjY0N3nvvPajV6hqFJiLAvZEZVo9sDyOZgP1RKVj04zV+M4yIqA7UqADNmzcPa9aswfLlyxEZGYnIyEi8//77WL16NRYsWFDbGYkMylPNHfDJS34QBGDbmQR89NtNqSMRETU4NboE5uLigg0bNmhWgX/ohx9+wLRp03D37t1aCygFXgIjXfDN2US8s+8KAOCtvi0wrZe3xImIiHRbnV8Cy87OrnKis6+vL7Kzs2uySyL6m1GBTTC3X8V/Zx8evIltp+OlDURE1IDUqAD5+flhzZo1j4yvWbMG7dq1e6J9rV27Fp6enjAxMUFgYCDOnTv32G3LysqwZMkSNGvWDCYmJvDz88PBgwe12ieRLpvcsxlee7rizM+CH65hX2SyxImIiBoGo5q86MMPP8SAAQNw6NAhzT2ATp8+jaSkJBw4cKDa+9m1axdmz56NDRs2IDAwECtXrkRISMhjF1WdP38+tm/fjk2bNsHX1xe//fYbhgwZglOnTmnuP/Sk+yTSdbOfaY784nJsORWPOXsuw0xhhJDWTlLHIiLSazX+GnxKSgrWrl2LGzduAABatmyJSZMm4X//+x8+//zzau0jMDAQnTp10pxNUqvVcHd3x2uvvYa33377ke1dXFwwb948TJ8+XTM2bNgwmJqaYvv27TXaZ1U4B4h0jVot4q29l/FdRDIUchm+Gt8J3X3spY5FRKRTnuT3d43OAAEVZWTp0qWVxi5duoQvv/yyWgWotLQUERERmDt3rmZMJpMhODgYp0+frvI1JSUlMDExqTRmamqKEydO1HifD/dbUlKi+TkvL+9f8xPVJ5lMwPKhbVFYUo5fr6Zh4tcXsP3VzgjwaCR1NCIivVSjOUC1ITMzEyqVCo6OjpXGHR0dkZaWVuVrQkJCsGLFCty+fRtqtRqhoaH4/vvvkZqaWuN9AsCyZctgbW2tebi7u2v56Yhqn5FchpUj/PFUcwc8KFNh/ObzuJaSK3UsIiK9JFkBqonPPvsMPj4+8PX1hUKhwIwZMzBhwgTNUhw1NXfuXOTm5moeSUlJtZSYqHYpjeTYOCYAnTxtkV9cjtFfnEVUUo7UsYiI9I5kBcje3h5yuRzp6emVxtPT0+HkVPUETwcHB+zfvx+FhYVISEjAjRs3YGFhAS8vrxrvEwCUSiWsrKwqPYh0lalCji/Hd4K/uw1yisowetMZnIrJlDoWEZFeeaI5QEOHDv3H53Nycqq9L4VCgYCAAISFhWHw4MEAKiYsh4WFYcaMGf/4WhMTE7i6uqKsrAx79+7FSy+9pPU+ifSJlYkxdrwaiMnbInAiJhPjN5/H6lHt+e0wIqJqeqICZG1t/a/Pjxs3rtr7mz17Nl5++WV07NgRnTt3xsqVK1FYWIgJEyYAAMaNGwdXV1csW7YMAHD27FncvXsX/v7+uHv3LhYvXgy1Wo233nqr2vskaijMlUb4cnxHvP5tFA5eS8PU7RH48AU/vBDQcBYmJiKqK09UgDZv3lyrbz58+HDcu3cPCxcuRFpaGvz9/XHw4EHNJObExMRK83uKi4sxf/58xMbGwsLCAv3798e2bdtgY2NT7X0SNSRKIznWjGqPud9fwZ6IZMzZcwl5D8rwSvemUkcjItJpNb4PUEPG+wCRvhFFEUt/icYXJ+IAADP7+OCNYB8IgiBxMiKi+lPna4ERkW4RBAHzBrTEnGebAwBWhd3Guz9dh1rN/78hIqoKCxBRAyEIAmY87YP3BrWGIABbTsXjzT2XUKZSSx2NiEjnsAARNTBjgzyxcrg/5DIB+yLvYur2CBSXqaSORUSkU1iAiBqgQf6u+HxsAJRGMhyKzsDEry+wBBER/QULEFED1aelIzZP6ARTYzmO387EK1vOo6i0XOpYREQ6gQWIqAHr2sweW1/pDHOFHKfuZGH8V+dRUMISRETEAkTUwHVu2gjbXg2EpYkRzsVnY9yXZ5FXXCZ1LCIiSbEAERmADk1s8c2rXWBtaoyLiTkY88VZ5BSVSh2LiEgyLEBEBqKtmzW+ndgFjcwVuJyci1GbziK7kCWIiAwTCxCRAWnlYoVvJ3aBvYUS11PzMPLzM7iXXyJ1LCKiescCRGRgWjhZYuekLmhsqcTN9HyM+Pw00vOKpY5FRFSvWICIDJB3YwvsnhwEF2sT3LlXiOEbTyM194HUsYiI6g0LEJGB8rQ3x67JQXCzNUV8VhFGfH4GKTksQURkGFiAiAyYeyMz7JochCaNzJDwRwm6yxJERAaABYjIwLnamGLnpC7wsDNDYnYRRnx+Gsn3i6SORURUp1iAiAguf5QgTzszJGU/wIjPzyApmyWIiBouFiAiAgA4W5ti56QgNLU3R/J9liAiathYgIhIw8naBN9O7AIve3PczakoQYlZLEFE1PCwABFRJU7WJvh2Uhd4OTwsQaeRkFUodSwiolrFAkREj3C0MsHOiV3QzMEcKbnFGPH5GcRnsgQRUcPBAkREVWpsVXEmyLuxBVL/KEF37hVIHYuIqFawABHRYzW2rJgT5NPYAml5xXhh/SlEJNyXOhYRkdZYgIjoHzlYKrFzUhf4udvgflEZRm06g9Dr6VLHIiLSCgsQEf0rOwslvp0YiKd9G6OkXI3J2y5gx9kEqWMREdUYCxARVYuZwgifjw3AiE7uUIvAvH1X8cnvNyGKotTRiIieGAsQEVWbkVyGZUPbYlawDwBg9eEY/N93l1GmUkucjIjoybAAEdETEQQBs4KbY/nQtpDLBHwXkYxXt15AYUm51NGIiKqNBYiIamRE5ybYNC4ApsZyhN+6hxGfn8G9/BKpYxERVQsLEBHV2NO+jvh2Uhc0Mlfgyt1cDF1/ErG8VxAR6QEWICLSir+7DfZO7YomjSpWkh+09iSO3syQOhYR0T9iASIirTW1N8feqV0R4GGL/OJyTNhyHuuP3uE3xIhIZ7EAEVGtcLBU4puJgRjZ2R2iCHxw8AZm7ozCg1KV1NGIiB7BAkREtUZpJMf7Q9rivcFtYCQT8NOlFAxbfwpJ2UVSRyMiqoQFiIhqlSAIGNvFAzteDYSduQLXU/MwaO1JnL6TJXU0IiINFiAiqhOBXnb46bXuaONqhezCUoz58iy2nIzjvCAi0gksQERUZ1xsTPHdlK4Y7O8ClVrE4p+u463vLqO4jPOCiEhaLEBEVKdMjOX4dLg/5vVvCZkA7IlIxvCNpzkviIgkxQJERHVOEARMfMoLW1/pDGtTY1xKzsWAVccRej1d6mhEZKBYgIio3vTwccAvM7vDz90GecXlmPj1Bbx/IJqLqRJRvWMBIqJ65WZrhj2Tg/BKt6YAgM+PxWLE52eQmvtA4mREZEhYgIio3imMZFg4sBU2jOkAS6URIhLuo/9nx7mEBhHVGxYgIpJM3zbO+HlmxVfl7xeVYfzm8/j4t5so5yUxIqpjLEBEJCkPO3N8N6UrxnRpAgBYcyQGY748i4y8YomTEVFDxgJERJIzMZbjf4PbYtXI9jBXyHEmNhv9Vx3HyZhMqaMRUQPFAkREOuN5Pxf8+Fp3+DpZIrOg4u7RK0JvQaXm3aOJqHaxABGRTmnmYIH907tpVpVfFXYbY77gJTEiql0sQESkc0yM5Vg2tB1WDveHmUKO07FZ6L/qBC+JEVGtYQEiIp01uL0rfpzRHS0cLZFZUIIxX57Fp7wkRkS1gAWIiHSad+OKS2IjOlVcEvvs4SWxfF4SI6KaYwEiIp1nqpBj+bB2+HS435+XxD7jJTEiqjkWICLSG0Pauz1ySeydfVeQW1QmdTQi0jMsQESkVx5eEhvZuQlEEfjmbCL6rDiK/ZF3IYqcG0RE1cMCRER6x1Qhx7KhbbFzUhd4N7ZAZkEpZu2KwugvzuLOvQKp4xGRHmABIiK91cXLDgdm9sD/hbSA0kiGU3ey0G/lcawIvYXiMpXU8YhIh7EAEZFeUxjJML23N0Lf6IleLRxQqlJjVdht9F15DMdv35M6HhHpKBYgImoQmtiZYfP4Tlg/ugMcrZSIzyrC2C/P4bVvI5GS80DqeESkYwSRswYfkZeXB2tra+Tm5sLKykrqOET0hPKLy7Ai9Ba2noqHWqw4S/RykAem9fKGrblC6nhEVEee5Pc3C1AVWICIGoard3Px3s/XcTYuGwBgaWKEKT2bYUI3T5gpjCROR0S17Ul+f0t+CWzt2rXw9PSEiYkJAgMDce7cuX/cfuXKlWjRogVMTU3h7u6ON954A8XFf94RdvHixRAEodLD19e3rj8GEemgNq7W2DmpCzZP6ISWzlbILy7HR7/dRM+PjmL7mQSUqdRSRyQiiUj6v0C7du3C7NmzsWHDBgQGBmLlypUICQnBzZs30bhx40e2/+abb/D222/jq6++QteuXXHr1i2MHz8egiBgxYoVmu1at26NQ4cOaX42MuL/6REZKkEQ0LtFY/T0ccCPl1LwSehNJGU/wPz9V/HliTi8+WxzDGjrDEEQpI5KRPVI0jNAK1aswMSJEzFhwgS0atUKGzZsgJmZGb766qsqtz916hS6deuGUaNGwdPTE88++yxGjhz5yFkjIyMjODk5aR729vb18XGISIfJZAIGt3dF2OxeWDywFezMFYjLLMSMbyLx/JqTXFaDyMBIVoBKS0sRERGB4ODgP8PIZAgODsbp06erfE3Xrl0RERGhKTyxsbE4cOAA+vfvX2m727dvw8XFBV5eXhg9ejQSExP/MUtJSQny8vIqPYioYVIYyTC+W1OEv9Ubs4J9YK6Q48rdXIz+4izGfnkWV+/mSh2RiOqBZAUoMzMTKpUKjo6OlcYdHR2RlpZW5WtGjRqFJUuWoHv37jA2NkazZs3Qq1cvvPPOO5ptAgMDsWXLFhw8eBDr169HXFwcevTogfz8/MdmWbZsGaytrTUPd3f32vmQRKSzLJRGmBXcHOFv9cb4rp4wlgs4fjsTz60+gZnfRiIxq0jqiERUhySfBP0kjh49ivfffx/r1q3DxYsX8f333+OXX37Be++9p9mmX79+ePHFF9GuXTuEhITgwIEDyMnJwe7dux+737lz5yI3N1fzSEpKqo+PQ0Q6wN5CicXPt0bY7F4Y7O8CAPjxUgr6rDiKxT9eQ2ZBicQJiaguSDY72N7eHnK5HOnp6ZXG09PT4eTkVOVrFixYgLFjx+LVV18FALRt2xaFhYWYNGkS5s2bB5ns0T5nY2OD5s2bIyYm5rFZlEollEqlFp+GiPRdEzszrBzRHq/28MKHv93EsVv3sOVUPPZcSMLEp7zwag8vWCj5hQqihkKyM0AKhQIBAQEICwvTjKnVaoSFhSEoKKjK1xQVFT1ScuRyOQA8dhXogoIC3LlzB87OzrWUnIgasjau1vj6lc745tVAtHOzRmGpCisP3Uavj45g88k4rjFG1EBIegls9uzZ2LRpE7Zu3Yro6GhMnToVhYWFmDBhAgBg3LhxmDt3rmb7gQMHYv369di5cyfi4uIQGhqKBQsWYODAgZoiNGfOHISHhyM+Ph6nTp3CkCFDIJfLMXLkSEk+IxHpp67e9vhhejesHdUBnnZmyCwoxbs/XUfPj45g66l4FiEiPSfp+dzhw4fj3r17WLhwIdLS0uDv74+DBw9qJkYnJiZWOuMzf/58CIKA+fPn4+7du3BwcMDAgQOxdOlSzTbJyckYOXIksrKy4ODggO7du+PMmTNwcHCo989HRPpNEAQMaOeMZ1s7YveFJKw9HIOU3GIs+vEa1h+9g2m9m+Glju4wMZZLHZWInhCXwqgCl8IgoqqUlKuw50Iy1h6JQWpuxR3onaxMML13M7zUyR1KIxYhIilxLTAtsQAR0T8pKVdh94VkrPtLEXK2NsG03t54qaMbixCRRFiAtMQCRETVUVKuwq7zSVh35A7S8iqKkKuNKWY/0xyD27tCLuPyGkT1iQVISyxARPQkisv+KEJHY5CeV3HfIF8nS/y3ny96NXfgOmNE9YQFSEssQERUE8VlKmw+GY91R2OQX1wOAAjyssPc/r5o52YjbTgiA8ACpCUWICLSRk5RKdYeicHWUwkoVakBAAPaOeP/nm0BT3tzidMRNVwsQFpiASKi2pB8vwgrQm9hX+RdiCJgJBMwOrAJXuvjA3sL3n2eqLaxAGmJBYiIatP1lDx8cPAGwm/dAwCYKeQY2bkJXuneFK42phKnI2o4WIC0xAJERHXhVEwmlh+8gcvJuQAqzgg97+eCST294OvEv2uItMUCpCUWICKqK6Io4tjtTGwMv4NTd7I0471aOGDyU83QxasRvzVGVEMsQFpiASKi+nA5OQcbj8Xi1yupUP/xN7GfmzUm92yGkNZOvI8Q0RNiAdISCxAR1aeErEJ8cTwOuy8koaS84ltjHnZmGNvFAy8EuMHGTCFxQiL9wAKkJRYgIpJCVkEJtp5OwNen45FTVAYAUBrJMNDPBaMDm8Df3YaXx4j+AQuQlliAiEhKRaXl2Bd5F9vPJCI6NU8z3trFCmO6eGCQvwvMFEYSJiTSTSxAWmIBIiJdIIoiLibmYMeZBPx8JRWlf1wes1QaYWgHV4zp4gEfR0uJUxLpDhYgLbEAEZGuyS4sxXcRSdhxNhEJWUWa8e7e9pjc0wvdve15eYwMHguQlliAiEhXqdUiTsRkYvuZBByKTtd8e6yVsxUm9/TCgLbOMJLLpA1JJBEWIC2xABGRPkjKLsKXJ+Kw63wSHpSpAACuNqZ4tUdTDO/kznlCZHBYgLTEAkRE+uR+YSm2nUnAllPxyC4sBQDYmBljXBcPjOvqyXXHyGCwAGmJBYiI9FFxmQp7IpLxxfFYzTwhpZEML3V0x+SeXnCzNZM4IVHdYgHSEgsQEekzlVrEb9fSsDH8Di79Zd2xYR3cMK13M3jYmUuckKhusABpiQWIiBoCURRxOjYLaw7HaNYdkwnAIH9XTO/dDN6N+RV6alhYgLTEAkREDU1EQjZWH47B0Zv3AACCAPRv44wZT3ujpTP/nqOGgQVISyxARNRQXU7OwZrDMfj9erpmLLilI1572ht+7jbSBSOqBSxAWmIBIqKGLjo1D2uOxODAlVQ8/C3Qw8ce03t7I7BpI95UkfQSC5CWWICIyFDEZBRg3ZEY/HApBao/7qrY0cMW03t7o1cLBxYh0issQFpiASIiQ5OUXYQN4Xew50IySlUVa461drHC9N7eCGntBLmMRYh0HwuQlliAiMhQpecV44vjsdhxNhFFpRV3l27mYI6pvbwxyN8Fxlxmg3QYC5CWWICIyNDdLyzF5lPx2HIyDnnF5QAqltmY8bQ3hnVwg8KIRYh0DwuQlliAiIgq5BeXYcfZRHxxPA6ZBSUAKorQ9N7eeCGARYh0CwuQlliAiIgqKy5T4dtziVh/9A4y8v8sQtN6N8OLAe4sQqQTWIC0xAJERFQ1FiHSZSxAWmIBIiL6Z8VlKuw8l4h1fylCLtYmmPbHpTETY7nECckQsQBpiQWIiKh6qipC9hYKjO3iibFBHmhkrpA4IRkSFiAtsQARET2Z4jIVdp1PwsbwO0jJLQYAKI1kGBbghv90b4pmDhYSJyRDwAKkJRYgIqKaKVOpceBKKr44Hocrd3M148EtG+M/3b3QxYvLbFDdYQHSEgsQEZF2RFHEubhsbDoeh7Ab6Zr1xtq4WmFiDy/0b+vMmypSrWMB0hILEBFR7Ym9V4AvT8Rh78VkFJdVLLPhaKXEmEAPjAxsAnsLpcQJqaFgAdISCxARUe3LLizFjjMJ2Ho6QXNTRYVchoF+Lhjf1RNt3awlTkj6jgVISyxARER1p7S8Yp7Q5lPxuJSUoxkP8LDF+K6e6NvGiZfHqEZYgLTEAkREVD8iE+9j66l4/HIlFWWqil9HjlZKjO3igZGdm8COl8foCbAAaYkFiIiofmXkFWPH2UTsOJuouTxmYizDiE5NMOkpL7jYmEqckPQBC5CWWICIiKRRUq7Cr1fS8NXJOFxOrvgavbFcwJD2rpjSsxm8eD8h+gcsQFpiASIikpYoijgZk4W1R2JwOjYLACAIQP+2zpjWqxlau3DCND2KBUhLLEBERLojIuE+1h+NwaHoDM1Y7xYOmN7bGx09G0mYjHQNC5CWWICIiHRPdGoe1h+9g58vp0D9x2+uTp62mNjDC8EtHSGT8Q7Tho4FSEssQEREuis+sxAbj93BdxHJmm+ONbU3xyvdm+KFDm4wVXAlekPFAqQlFiAiIt2XlluMrafjseNMAvKKywEANmbGGBPogXFdPdDY0kTihFTfWIC0xAJERKQ/CkvKsedCEr46GY/E7CIAFXeYHuTvgv/0aApfJ/49bihYgLTEAkREpH9UahGh19Ow6XgcIhLua8Z7+NhjbBcPPO3bGEa8w3SDxgKkJRYgIiL9djHxPr48Hodfr6ZqJky7WJtgZOcmGN7ZnZfHGigWIC2xABERNQxJ2UXYfjYBey4kI7uwFABgJBMQ0toJo7s0QZCXHQSB3x5rKFiAtMQCRETUsBSXqXDwahq2nUmodHmsmYM5Rgd6YFiAG6xNjSVMSLWBBUhLLEBERA1XdGoetp9JwP7IuygsVQGoWHesXxtnvBDghiAvO95TSE+xAGmJBYiIqOErKCnHvsi72HEmATfS8jXjLtYmGBbghmEd3OBpby5hQnpSLEBaYgEiIjIcoigiKikHey8m48eoFM09hYCKO02/EOCG/m2dYWnCS2S6jgVISyxARESGqbhMhUPR6fguIhnHbt3TfIPMxFiGvq2dMLi9K7p528OYX6fXSSxAWmIBIiKi9Lxi7I+8iz0RyYjJKNCMNzJXoF8bJzzv54JOno04X0iHsABpiQWIiIgeEkURl5NzsfdiMg5cSUVmQanmOScrEzzXzhkD/VzQzs2aX6mX2JP8/pb8HN7atWvh6ekJExMTBAYG4ty5c/+4/cqVK9GiRQuYmprC3d0db7zxBoqLi7XaJxER0eMIggA/dxssGdQGZ+b2wbb/dMaLAW6wNDFCWl4xvjgRh0FrT6LXx0fx8W83EZ2aB55b0H2SngHatWsXxo0bhw0bNiAwMBArV67Enj17cPPmTTRu3PiR7b/55hu88sor+Oqrr9C1a1fcunUL48ePx4gRI7BixYoa7bMqPANERET/pqRchfCb9/DjpRQcik5HcZla85x7I1M809IJz7Z2REcPWy7BUU/05hJYYGAgOnXqhDVr1gAA1Go13N3d8dprr+Htt99+ZPsZM2YgOjoaYWFhmrE333wTZ8+exYkTJ2q0z6qwABER0ZMoLCnHoeh0/HQpFcdv30NJ+Z9lyNbMGE/7OuKZVo54qrk9zBRGEiZt2J7k97dk/xZKS0sRERGBuXPnasZkMhmCg4Nx+vTpKl/TtWtXbN++HefOnUPnzp0RGxuLAwcOYOzYsTXeJwCUlJSgpKRE83NeXp62H4+IiAyIudIIg/xdMcjfFUWl5Th2KxOh19MRdiMd94vKsPdiMvZeTIbSSIYePvZ4ppUjerdojMZWXJNMKpIVoMzMTKhUKjg6OlYad3R0xI0bN6p8zahRo5CZmYnu3btDFEWUl5djypQpeOedd2q8TwBYtmwZ3n33XS0/EREREWCmMELfNk7o28YJ5So1LiTcx+/X0hEanYak7Ac4FJ2BQ9EZAIDWLlZ42rcxevs2hp+bDeT8Rlm90avzcEePHsX777+PdevWITAwEDExMXj99dfx3nvvYcGCBTXe79y5czF79mzNz3l5eXB3d6+NyEREZMCM5DJ08bJDFy87LHiuJW6m5+P3a+kIu5GBy8k5uJaSh2speVh9OAaNzBXo2dwBvVo4oGdzB9iYKaSO36BJVoDs7e0hl8uRnp5eaTw9PR1OTk5VvmbBggUYO3YsXn31VQBA27ZtUVhYiEmTJmHevHk12icAKJVKKJVKLT8RERHR4wmCAF8nK/g6WWFmHx9kFpQg/OY9HL6ZgWO37iG7sBT7Iu9iX+RdyAQgwMMWwS0r5g55OVhIHb/BkWxaukKhQEBAQKUJzWq1GmFhYQgKCqryNUVFRZDJKkeWy+UAKu7TUJN9EhERScHeQolhAW5YO6oDIhc8g12TumByTy+0cLSEWgTOx9/Hsl9v4OlPwtHnk6NY/usNRCTch1rNr9jXBkkvgc2ePRsvv/wyOnbsiM6dO2PlypUoLCzEhAkTAADjxo2Dq6srli1bBgAYOHAgVqxYgfbt22sugS1YsAADBw7UFKF/2ycREZGuMZLLEOhlh0AvO8zt1xLJ94tw+EYGQq+n4/SdLNy5V4g74XewIfwO7C0U6PPHt8q6+9jDxFgudXy9JGkBGj58OO7du4eFCxciLS0N/v7+OHjwoGYSc2JiYqUzPvPnz4cgCJg/fz7u3r0LBwcHDBw4EEuXLq32PomIiHSdm60ZxgV5YlyQJ/KKy3D05j2EXk/H0RsZyCwoxa4LSdh1IQmmxnL09nVA/7bOeNq3Mb9i/wS4FEYVeB8gIiLSRaXlapyLy0bo9TSEXk9HSu6fKyGYGMvQq3lj9G9XUYYslIZXhvTmRoi6igWIiIh0nSiKuHo3D79cScWBK6lIzC7SPKc0kqFn84ozQ31aNoalibGESesPC5CWWICIiEifiKKIayl5+PVqKg5cSUNcZqHmOYWRDE/5OKB/Wyf0aekIa9OGW4ZYgLTEAkRERPpKFEXcSMvHgSup+OVKKmLv/VmGjOUCunvbo39bZzzTyrHB3WuIBUhLLEBERNQQiKKIW+kFOHAlFb9eTcWt9ALNc0YyAV297TGgrROeaeWERub6X4ZYgLTEAkRERA1RTEY+DlxJw4ErqbiRlq8Zl8sEBHjYooe3Pbr52KOdq7VermDPAqQlFiAiImroYu8V4NerFWXoWkrlRcAtTYwQ5GWH7j726OZtDy97cwiC7q9TxgKkJRYgIiIyJIlZRTh2+x5OxmTi1J0s5D4oq/S8i7UJunnbo6u3HTo3tYOrjalESf8ZC5CWWICIiMhQqdQirqXk4vjtTJyMycSF+PsoVakrbeNqY4rOTRuhc9NG6OTZCM0cdOMMEQuQlliAiIiIKjwoVeF8fDZOxGTibGwWrqbkQfW39cjszBXo5NlIU4p8nSwlmUPEAqQlFiAiIqKqFZaU42LifZyPy8bZuGxEJuWgtLzyGSIzhRz+7jYI8LBFgIct2jexrZf7D7EAaYkFiIiIqHpKylW4kpyLs3HZOB+fjYj4+8gvKX9ku+aOFgjwsEWHJrbo6NkInnZmtX7ZjAVISyxARERENaNSi7idkY+IhPuISLiPiwn3EZ9V9Mh2Izq5Y/mwdrX63k/y+9vwVkojIiKiOiOXCfB1soKvkxVGB3oAADILSjRlKCLhPi7fzUUrF2lPMLAAERERUZ2yt1AipLUTQlo7Aai4bPb3idT1jQWIiIiI6pXSSC51BOjffa6JiIiItMQCRERERAaHBYiIiIgMDgsQERERGRwWICIiIjI4LEBERERkcFiAiIiIyOCwABEREZHBYQEiIiIig8MCRERERAaHBYiIiIgMDgsQERERGRwWICIiIjI4XA2+CqIoAgDy8vIkTkJERETV9fD39sPf4/+EBagK+fn5AAB3d3eJkxAREdGTys/Ph7W19T9uI4jVqUkGRq1WIyUlBZaWlhAEoVb3nZeXB3d3dyQlJcHKyqpW902P4vGuXzze9YvHu37xeNevmhxvURSRn58PFxcXyGT/PMuHZ4CqIJPJ4ObmVqfvYWVlxf+A6hGPd/3i8a5fPN71i8e7fj3p8f63Mz8PcRI0ERERGRwWICIiIjI4LED1TKlUYtGiRVAqlVJHMQg83vWLx7t+8XjXLx7v+lXXx5uToImIiMjg8AwQERERGRwWICIiIjI4LEBERERkcFiAiIiIyOCwANWjtWvXwtPTEyYmJggMDMS5c+ekjtQgHDt2DAMHDoSLiwsEQcD+/fsrPS+KIhYuXAhnZ2eYmpoiODgYt2/fliZsA7Bs2TJ06tQJlpaWaNy4MQYPHoybN29W2qa4uBjTp0+HnZ0dLCwsMGzYMKSnp0uUWL+tX78e7dq109wMLigoCL/++qvmeR7rurV8+XIIgoBZs2ZpxnjMa8/ixYshCEKlh6+vr+b5ujzWLED1ZNeuXZg9ezYWLVqEixcvws/PDyEhIcjIyJA6mt4rLCyEn58f1q5dW+XzH374IVatWoUNGzbg7NmzMDc3R0hICIqLi+s5acMQHh6O6dOn48yZMwgNDUVZWRmeffZZFBYWarZ544038NNPP2HPnj0IDw9HSkoKhg4dKmFq/eXm5obly5cjIiICFy5cwNNPP41Bgwbh2rVrAHis69L58+exceNGtGvXrtI4j3ntat26NVJTUzWPEydOaJ6r02MtUr3o3LmzOH36dM3PKpVKdHFxEZctWyZhqoYHgLhv3z7Nz2q1WnRychI/+ugjzVhOTo6oVCrFb7/9VoKEDU9GRoYIQAwPDxdFseL4Ghsbi3v27NFsEx0dLQIQT58+LVXMBsXW1lb84osveKzrUH5+vujj4yOGhoaKPXv2FF9//XVRFPnnu7YtWrRI9PPzq/K5uj7WPANUD0pLSxEREYHg4GDNmEwmQ3BwME6fPi1hsoYvLi4OaWlplY69tbU1AgMDeexrSW5uLgCgUaNGAICIiAiUlZVVOua+vr5o0qQJj7mWVCoVdu7cicLCQgQFBfFY16Hp06djwIABlY4twD/fdeH27dtwcXGBl5cXRo8ejcTERAB1f6y5GGo9yMzMhEqlgqOjY6VxR0dH3LhxQ6JUhiEtLQ0Aqjz2D5+jmlOr1Zg1axa6deuGNm3aAKg45gqFAjY2NpW25TGvuStXriAoKAjFxcWwsLDAvn370KpVK0RFRfFY14GdO3fi4sWLOH/+/CPP8c937QoMDMSWLVvQokULpKam4t1330WPHj1w9erVOj/WLEBEVGPTp0/H1atXK12zp9rXokULREVFITc3F9999x1efvllhIeHSx2rQUpKSsLrr7+O0NBQmJiYSB2nwevXr5/mn9u1a4fAwEB4eHhg9+7dMDU1rdP35iWwemBvbw+5XP7IzPX09HQ4OTlJlMowPDy+PPa1b8aMGfj5559x5MgRuLm5acadnJxQWlqKnJycStvzmNecQqGAt7c3AgICsGzZMvj5+eGzzz7jsa4DERERyMjIQIcOHWBkZAQjIyOEh4dj1apVMDIygqOjI495HbKxsUHz5s0RExNT53++WYDqgUKhQEBAAMLCwjRjarUaYWFhCAoKkjBZw9e0aVM4OTlVOvZ5eXk4e/Ysj30NiaKIGTNmYN++fTh8+DCaNm1a6fmAgAAYGxtXOuY3b95EYmIij3ktUavVKCkp4bGuA3369MGVK1cQFRWleXTs2BGjR4/W/DOPed0pKCjAnTt34OzsXPd/vrWeRk3VsnPnTlGpVIpbtmwRr1+/Lk6aNEm0sbER09LSpI6m9/Lz88XIyEgxMjJSBCCuWLFCjIyMFBMSEkRRFMXly5eLNjY24g8//CBevnxZHDRokNi0aVPxwYMHEifXT1OnThWtra3Fo0ePiqmpqZpHUVGRZpspU6aITZo0EQ8fPixeuHBBDAoKEoOCgiRMrb/efvttMTw8XIyLixMvX74svv3226IgCOLvv/8uiiKPdX3467fARJHHvDa9+eab4tGjR8W4uDjx5MmTYnBwsGhvby9mZGSIoli3x5oFqB6tXr1abNKkiahQKMTOnTuLZ86ckTpSg3DkyBERwCOPl19+WRTFiq/CL1iwQHR0dBSVSqXYp08f8ebNm9KG1mNVHWsA4ubNmzXbPHjwQJw2bZpoa2srmpmZiUOGDBFTU1OlC63HXnnlFdHDw0NUKBSig4OD2KdPH035EUUe6/rw9wLEY157hg8fLjo7O4sKhUJ0dXUVhw8fLsbExGier8tjLYiiKGp/HomIiIhIf3AOEBERERkcFiAiIiIyOCxAREREZHBYgIiIiMjgsAARERGRwWEBIiIiIoPDAkREREQGhwWIiKgKnp6eWLlypdQxiKiOsAARkeTGjx+PwYMHAwB69eqFWbNm1dt7b9myBTY2No+Mnz9/HpMmTaq3HERUv4ykDkBEVBdKS0uhUChq/HoHB4daTENEuoZngIhIZ4wfPx7h4eH47LPPIAgCBEFAfHw8AODq1avo168fLCws4OjoiLFjxyIzM1Pz2l69emHGjBmYNWsW7O3tERISAgBYsWIF2rZtC3Nzc7i7u2PatGkoKCgAABw9ehQTJkxAbm6u5v0WL14M4NFLYImJiRg0aBAsLCxgZWWFl156Cenp6ZrnFy9eDH9/f2zbtg2enp6wtrbGiBEjkJ+fX7cHjYhqhAWIiHTGZ599hqCgIEycOBGpqalITU2Fu7s7cnJy8PTTT6N9+/a4cOECDh48iPT0dLz00kuVXr9161YoFAqcPHkSGzZsAADIZDKsWrUK165dw9atW3H48GG89dZbAICuXbti5cqVsLKy0rzfnDlzHsmlVqsxaNAgZGdnIzw8HKGhoYiNjcXw4cMrbXfnzh3s378fP//8M37++WeEh4dj+fLldXS0iEgbvARGRDrD2toaCoUCZmZmcHJy0oyvWbMG7du3x/vvv68Z++qrr+Du7o5bt26hefPmAAAfHx98+OGHlfb51/lEnp6e+N///ocpU6Zg3bp1UCgUsLa2hiAIld7v78LCwnDlyhXExcXB3d0dAPD111+jdevWOH/+PDp16gSgoiht2bIFlpaWAICxY8ciLCwMS5cu1e7AEFGt4xkgItJ5ly5dwpEjR2BhYaF5+Pr6Aqg46/JQQEDAI689dOgQ+vTpA1dXV1haWmLs2LHIyspCUVFRtd8/Ojoa7u7umvIDAK1atYKNjQ2io6M1Y56enpryAwDOzs7IyMh4os9KRPWDZ4CISOcVFBRg4MCB+OCDDx55ztnZWfPP5ubmlZ6Lj4/Hc889h6lTp2Lp0qVo1KgRTpw4gf/85z8oLS2FmZlZreY0Njau9LMgCFCr1bX6HkRUO1iAiEinKBQKqFSqSmMdOnTA3r174enpCSOj6v+1FRERAbVajU8++QQyWcUJ7927d//r+/1dy5YtkZSUhKSkJM1ZoOvXryMnJwetWrWqdh4i0h28BEZEOsXT0xNnz55FfHw8MjMzoVarMX36dGRnZ2PkyJE4f/487ty5g99++w0TJkz4x/Li7e2NsrIyrF69GrGxsdi2bZtmcvRf36+goABhYWHIzMys8tJYcHAw2rZti9GjR+PixYs4d+4cxo0bh549e6Jjx461fgyIqO6xABGRTpkzZw7kcjlatWoFBwcHJCYmwsXFBSdPnoRKpcKzzz6Ltm3bYtasWbCxsdGc2amKn58fVqxYgQ8++ABt2rTBjh07sGzZskrbdO3aFVOmTMHw4cPh4ODwyCRqoOJS1g8//ABbW1s89dRTCA4OhpeXF3bt2lXrn5+I6ocgiqIodQgiIiKi+sQzQERERGRwWICIiIjI4LAAERERkcFhASIiIiKDwwJEREREBocFiIiIiAwOCxAREREZHBYgIiIiMjgsQERERGRwWICIiIjI4LAAERERkcFhASIiIiKD8/9b49GhDlEIIgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(nn.losses)\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3yqRa1cdna"
      },
      "source": [
        "**Let's also check our model's performance using the `accuracy` metric on the `testing` dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRqwXho7cdnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a350cf-c011-4d71-b541-4f43f807eb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8294157152451309\n"
          ]
        }
      ],
      "source": [
        "# Compute the accuracy on the testing set\n",
        "#############################\n",
        "# Your code goes here (7 points)\n",
        "\n",
        "pred = nn.forward(x_test)\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "\n",
        "acc = np.sum(pred == y_test) / pred.shape[0]\n",
        "#############################\n",
        "\n",
        "print(acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}